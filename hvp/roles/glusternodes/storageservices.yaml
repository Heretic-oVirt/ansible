---
# Ansible playbook to configure and start Gluster-block and CTDB/Samba/Gluster-NFS for iSCSI/CIFS/NFS sharing
# TODO: substitute Gluster-NFS with NFS-Ganesha as soon as a proper CTDB-based configuration for NFS-Ganesha has been devised
- name: Generate SSH key if not present
  hosts: localhost
  tasks:
    - include_tasks: ../common/tasks/createkeys.yaml
- name: Inspect Gluster nodes
  hosts: glusternodes
  remote_user: root
  tasks:
    - include_tasks: ../common/tasks/setupkeys.yaml
    - name: Get common vars
      include_vars:
        file: "../common/vars/hvp.yaml"
- name: Prepare Gluster-volume based share dirs for CIFS
  hosts: gluster_master
  remote_user: root
  tasks:
    - name: Mount the Gluster volume intended for CIFS sharing
      command: "mount -t glusterfs localhost:/{{ hvp_winshare_volume_name }} /mnt"
      args:
        warn: no
      register: winsharemount_result
    - name: Create the toplevel folders intended for CIFS sharing
      file:
        path: "/mnt/{{ item.path }}"
        state: directory
        owner: "{{ item.owner }}"
        group: "{{ item.group }}"
        mode: "{{ item.mode }}"
      with_items: "{{ hvp_winshare_subfolders }}"
      when: winsharemount_result.rc == 0
    - name: Unmount the Gluster volume intended for CIFS sharing
      command: "umount -l /mnt"
      args:
        warn: no
      register: winshareumount_result
- name: Prepare Gluster-volume based share dirs for NFS
  hosts: gluster_master
  remote_user: root
  tasks:
    - name: Mount the Gluster volume intended for NFS sharing
      command: "mount -t glusterfs localhost:/{{ hvp_unixshare_volume_name }} /mnt"
      args:
        warn: no
      register: unixsharemount_result
    - name: Create the toplevel folders intended for NFS sharing
      file:
        path: "/mnt/{{ item.path }}"
        state: directory
        owner: "{{ item.owner }}"
        group: "{{ item.group }}"
        mode: "{{ item.mode }}"
      with_items: "{{ hvp_unixshare_subfolders }}"
      when: unixsharemount_result.rc == 0
    - name: Unmount the Gluster volume intended for NFS sharing
      command: "umount -l /mnt"
      args:
        warn: no
      register: unixshareumount_result
- name: Configure and start Gluster-block
  # TODO: given the problems with Gluster-block, we interpret an empty list of LUNs as a choice for disabling Gluster-block altogether - revert when fixed
  hosts: glusternodes
  remote_user: root
  tasks:
    - name: Remove spurious state file
      file:
        path: /etc/target/saveconfig.json
        state: absent
      when: (hvp_lun_sizes | length) > 0
    - name: Enable and start the Gluster-block service
      systemd:
        name: gluster-blockd
        enabled: true
        state: started
        no_block: no
      when: (hvp_lun_sizes | length) > 0
    - name: Disable and stop the Gluster-block service
      systemd:
        name: gluster-blockd
        enabled: false
        state: stopped
        no_block: no
      when: (hvp_lun_sizes | length) == 0
- name: Create Gluster-block based LUNs
  hosts: gluster_master
  remote_user: root
  tasks:
    - name: Create all Gluster-block based LUNs
      include_tasks: tasks/createlun.yaml
      when: (hvp_lun_sizes | length) > 0
      with_indexed_items: "{{ hvp_lun_sizes }}"
      loop_control:
        loop_var: outer_item
- name: Configure and start CTDB/Samba
  hosts: glusternodes
  remote_user: root
  tasks:
    - name: Enable and start the wait service for Gluster CTDB volume
      systemd:
        name: gluster-ctdb-wait-online
        enabled: true
        state: started
        no_block: no
    - name: Enable and start the local mounting of the Gluster CTDB volume
      systemd:
        name: gluster-lock.mount
        enabled: true
        state: started
        no_block: no
    - name: Enable and start the wait service for Gluster shared storage volume
      systemd:
        name: gluster-shared-storage-wait-online
        enabled: true
        state: started
        no_block: no
    - name: Enable and start the local mounting of the Gluster shared storage volume
      systemd:
        name: var-run-gluster-shared_storage.mount
        enabled: true
        state: started
        no_block: no
    - name: Enable and start the RT bandwidth configuration
      systemd:
        name: cgroup-rt-bandwidth
        enabled: true
        state: started
        no_block: no
    - name: Prepare Samba Workgroup configuration file
      template:
        src: templates/smb-workgroup.j2
        dest: /etc/samba/smb.conf
        owner: root
        group: root
        mode: 0644
    - name: Enable and start the CTDB service
      systemd:
        name: ctdb
        enabled: true
        state: started
        no_block: no
    - name: Initialize the snapshot scheduler
      command: snap_scheduler.py init
      retries: 60
      delay: 30
      register: snapschedinit_result
      until: snapschedinit_result is succeeded
- name: Configure Samba authentication and scheduled snapshot
  hosts: gluster_master
  remote_user: root
  tasks:
    - name: Wait for Samba to become ready on the host
      wait_for: port=445 timeout=300
    - name: Configure local root user
      shell: "echo -e '{{ ansible_ssh_pass }}\\n{{ ansible_ssh_pass }}\\n' | smbpasswd -s -a root"
      register: smbpasswd_result
    - name: Configure scheduled snapshots
      command: '{{ item }}'
      with_items:
        - "snap_scheduler.py enable"
        - "gluster --mode=script snapshot config {{ hvp_winshare_volume_name }} snap-max-hard-limit {{ hvp_share_snapshot_max }} auto-delete enable"
        - "gluster --mode=script snapshot config {{ hvp_unixshare_volume_name }} snap-max-hard-limit {{ hvp_share_snapshot_max }} auto-delete enable"
        - "snap_scheduler.py add 'Windows_schedule' '{{ hvp_share_snapshot_schedule }}' {{ hvp_winshare_volume_name }}"
        - "snap_scheduler.py add 'Unix_schedule' '{{ hvp_share_snapshot_schedule }}' {{ hvp_unixshare_volume_name }}"
...
