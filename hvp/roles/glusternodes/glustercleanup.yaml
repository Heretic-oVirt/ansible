---
# Ansible playbook for GlusterFS nodes unconfiguration (cleanup)
- name: Generate SSH key if not present
  hosts: localhost
  tasks:
    - include: ../common/tasks/createkeys.yaml
- name: inspect gluster nodes
  hosts: glusternodes
  remote_user: root
  tasks:
    - include: ../common/tasks/setupkeys.yaml
# TODO: write a suitable hvp_gluster_disks fact-finding module to drive the LVM-cleanup part in gdeploy-cleanup.j2
#    - name: gather Gluster-used disks
#      hvp_gluster_disks: include_ssd=1
    - name: get common vars
      include_vars:
        file: ../common/vars/hvp.yaml
- name: Delete Gluster-block based volumes
  hosts: gluster_master
  remote_user: root
  tasks:
    - name: get common vars
      include_vars:
        file: ../common/vars/hvp.yaml
    - name: enumerate Gluster-block based iSCSI LUNs
      command: "gluster-block list {{ hvp_blockshare_volume_name }}"
      ignore_errors: yes
      register: enumerateluns_result
    - name: delete all iSCSI LUNs found
      command: "gluster-block delete {{ hvp_blockshare_volume_name }}/{{ item }}"
      ignore_errors: yes
      register: deleteluns_result
      with_items:
        - "{{ enumerateluns_result.stdout_lines }}"
      when:
        - enumerateluns_result.rc == 0
- name: Stop and unconfigure Gluster-block
  hosts: glusternodes
  remote_user: root
  tasks:
    - name: get common vars
      include_vars:
        file: ../common/vars/hvp.yaml
    - name: disable and stop the Gluster-block service
      systemd:
        name: gluster-blockd
        enabled: False
        state: stopped
        no_block: no
      ignore_errors: yes
- name: Stop and unconfigure CTDB
  hosts: glusternodes
  remote_user: root
  tasks:
    - name: get common vars
      include_vars:
        file: ../common/vars/hvp.yaml
    - name: disable and stop the CTDB service
      systemd:
        name: ctdb
        enabled: False
        state: stopped
        no_block: no
    - name: disable and stop the RT bandwidth configuration
      systemd:
        name: cgroup-rt-bandwidth
        enabled: False
        state: stopped
        no_block: no
    - name: disable and stop the wait service for Gluster ctdb volume
      systemd:
        name: gluster-ctdb-wait-online
        enabled: False
        state: stopped
        no_block: no
    - name: disable and stop the local mounting of the Gluster ctdb volume
      systemd:
        name: gluster-lock.mount
        enabled: False
        state: stopped
        no_block: no
    - name: copy LVM cleanup helper script
      # TODO: remove when properly implemented by means of gDeploy
      copy:
        src: lvm-cleanup.sh
        dest: /usr/local/sbin/lvm-cleanup.sh
        owner: root
        group: root
        mode: 0755
- name: perform gdeploy-based Gluster unconfiguration
  hosts: localhost
  remote_user: root
  tasks:
    - name: get common vars
      include_vars:
        file: ../common/vars/hvp.yaml
    - name: prepare gdeploy cleanup configuration file
      template:
        src: templates/gdeploy-cleanup.j2
        dest: "{{ playbook_dir }}/gdeploy-cleanup.conf"
        owner: root
        group: root
        mode: 0644
    - name: perform actual gdeploy-based Gluster unconfiguration
      command: gdeploy -k -vv -c "{{ playbook_dir }}/gdeploy-cleanup.conf"
      register: gdeploy_cleanup_result
- name: perform LVM cleanup on nodes
  # TODO: remove when properly implemented by means of gDeploy
  hosts: glusternodes
  remote_user: root
  tasks:
    - name: get common vars
      include_vars:
        file: ../common/vars/hvp.yaml
    - name: execute LVM cleanup helper script
      vars:
        ansible_ssh_pipelining: no
      command: /usr/local/sbin/lvm-cleanup.sh
      register: lvmcleanup_result
...
