---
# Ansible playbook to properly startup a whole HVP cluster previously shut down using our playbook
- name: Generate SSH key if not present
  hosts: localhost
  tasks:
    - include_tasks: ../common/tasks/createkeys.yaml
- name: Perform initial poweron on all nodes
  # TODO: physically power on nodes, maybe using BMC access
  hosts: ovirtnodes
  remote_user: root
  tasks:
    - include_tasks: ../common/tasks/setupkeys.yaml
    - name: Get common vars from files
      include_vars:
        file: "../common/vars/hvp.yaml"
    - name: Make sure that basic needed services are up and running
      systemd:
        name: "{{ item }}"
        state: started
      with_items:
        - glusterd.service
- name: Start GlusterFS volumes
  hosts: ovirt_master
  remote_user: root
  tasks:
    - name: Start all GlusterFS volumes
      shell: "for volname in $(gluster volume list); do gluster --mode=script volume start ${volname} force ; sleep 5 ; done"
- name: Perform further startup actions on all nodes
  hosts: ovirtnodes
  remote_user: root
  tasks:
    - include_tasks: ../common/tasks/setupkeys.yaml
    - name: Restart Gluster-block services
      # TODO: given the problems with Gluster-block, we interpret an empty list of LUNs as a choice for disabling Gluster-block altogether - revert when fixed
      systemd:
        name: "{{ item }}"
        state: restarted
      with_items:
        - gluster-block-target.service
        - gluster-blockd.service
      loop_control:
        pause: 5
      when: (hvp_lun_sizes | length) > 0
    - name: Restart CTDB services
      systemd:
        name: "{{ item }}"
        state: restarted
      with_items:
        - gluster-lock.mount
        - ctdb.service
      loop_control:
        pause: 5
    - name: Restart oVirt HA services
      systemd:
        name: "{{ item }}"
        state: restarted
      with_items:
        - ovirt-ha-broker.service
        - ovirt-ha-agent.service
        - vdsmd.service
      loop_control:
        pause: 5
- name: Take oVirt Hosted Engine out of maintenance
  hosts: ovirt_master
  remote_user: root
  tasks:
    - include_tasks: ../common/tasks/setupkeys.yaml
    - name: Get common vars from files
      include_vars:
        file: "../common/vars/hvp.yaml"
    - name: Remove global maintenance
      vars:
        ansible_ssh_pipelining: no
      command: hosted-engine --set-maintenance --mode=none
      register: exitglobalmaintenance_result
    - name: Wait for good Engine health
      vars:
        ansible_ssh_pipelining: no
      shell: "hosted-engine --vm-status | grep -i good"
      retries: 60
      delay: 30
      register: enginehealth_result
      until: enginehealth_result is succeeded
- name: Perform final startup operations through the Engine
  hosts: ovirtengine
  remote_user: root
  tasks:
    - include_tasks: ../common/tasks/setupkeys.yaml
    - name: Get common vars from files
      include_vars:
        file: "../common/vars/hvp.yaml"
    - name: Obtain oVirt Engine SSO token
      no_log: true
      ovirt_auth:
        url: "{{ url }}"
        username: "{{ username }}"
        password: "{{ password }}"
        ca_file: "{{ ca_file }}"
    - name: Put main Datacenter storage domain out of maintenance
      ovirt_storage_domain:
        auth: "{{ ovirt_auth }}"
        name: "{{ vmstore_sd_name }}"
        data_center: "{{ dc_name }}"
        state: present
        wait: true
      retries: 60
      delay: 30
      register: sdenable_result
      until: sdenable_result.storagedomain.status == "active"
    - name: Wait for Datacenter to be operational
      ovirt_datacenter:
        auth: "{{ ovirt_auth }}"
        name: "{{ dc_name }}"
        state: present
        wait: true
      retries: 60
      delay: 30
      register: dcenable_result
      until: dcenable_result.datacenter.status == "up"
    - name: Put all remaining storage domains out of maintenance
      ovirt_storage_domain:
        auth: "{{ ovirt_auth }}"
        name: "{{ item }}"
        data_center: "{{ dc_name }}"
        state: present
        wait: true
      with_items:
        - "{{ iso_sd_name }}"
    - name: Startup all guest VMs
      # Note: ignoring errors to allow for non-existent VMs
      # TODO: check for VM existence and skip if missing
      ovirt_vm:
        auth: "{{ ovirt_auth }}"
        state: running
        cluster: "{{ cluster_name }}"
        name: "{{ item.vm_name }}"
        wait: true
      ignore_errors: true
      with_items: "{{ guest_vms }}"
    - name: Revoke the SSO token
      no_log: true
      ovirt_auth:
        state: absent
        ovirt_auth: "{{ ovirt_auth }}"
...
